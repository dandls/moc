indata[, nam[2:length(nam)]] = NULL
indata
str(indata)
class(mod) = "randomForest"
rules <- getRules(mod, ktree = 5L, resample = TRUE)
es.rf <- set.eSatisfactory(rules, epsiron = 0.3)
# Calculate cfexp for each row
targets = predict(mod, newdata = x.interests)
target.class = mod$classes
tweaked = mapply(function(x.interest, target, row.id) {
ytilde = target.class[-which(target %in% targets)]
res = tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE)
res.sug = res$suggest
res.sug$row_ids = row.id
res.sug
}, split(x.interests, seq(length(row.ids))), targets, row.ids,
SIMPLIFY = FALSE)
res.cf = do.call("rbind", tweaked)
ncols = ncol(res.cf)
cf = res.cf[, 1:(ncols-1)]
cf.classes = sapply(cf, class)
cf.classes = sapply(cf, class)
cf.classes
cf
pred$predictor$data$feature.types
pred$predictor$data$feature.types == "categorical"
names(pred$predictor$data$feature.types == "categorical")
pred$predictor$data$feature.types == "categorical"
# revert dummy encoding
pred$predictor$data$feature.types == "categorical"
# revert dummy encoding
head(pred$predictor$data$feature.types == "categorical")
# revert dummy encoding
which(pred$predictor$data$feature.types == "categorical")
# revert dummy encoding
names(which(pred$predictor$data$feature.types == "categorical"))
# revert dummy encoding
vars = names(which(pred$predictor$data$feature.types == "categorical"))
# revert dummy encoding
dum.vars = names(which(pred$predictor$data$feature.types == "categorical"))
revert_dummy <-function(var,indata){
nam = names(indata)[grepl(var, names(indata))]
col = indata[, nam]
nams = str_remove(names(col), var)
val = names(col)[apply(col, 1, function(i) which(i == 1))]
val = str_remove(val, var)
indata[, nam[1]] = factor(val, levels = nams)
names(indata)[names(indata) == nam[1]] <- var
indata[, nam[2:length(nam)]] = NULL
return(indata)
}
for (var in dum.vars) {
cf = revert_dummy(var, cf)
}
cf
cf
revert_dummy <-function(var,indata){
nam = names(indata)[grepl(var, names(indata))]
col = indata[, nam]
nams = str_remove(names(col), var)
val = names(col)[apply(col, 1, function(i) which(i == 1))]
val = str_remove(val, var)
indata[, nam[1]] = factor(val, levels = nams)
names(indata)[names(indata) == nam[1]] <- var
indata[, nam[2:length(nam)]] = NULL
return(indata)
}
feature_tweaking = function(pred) {
assert_true(pred$learner.id == "randomforest")
# Load info from folder
path = file.path("../../saved_objects/data",
pred$task.id)
row.ids = read.delim(file.path(path, "sampled_ids.txt"), header = FALSE)[,1]
df = read.csv(file.path(path, "data_encoded.csv"))
df = df[, !(names(df) %in% pred$predictor$data$y.names)]
df.classes = sapply(df, class)
center = read_json(file.path(path, "feature_center.json"))
scale = read_json(file.path(path, "feature_scale.json"))
x.interests = df[row.ids, ]
# Get model
mod = pred$predictor$model$learner.model$next.model$learner.model
class(mod) = "randomForest"
rules <- getRules(mod, ktree = 5L, resample = TRUE)
es.rf <- set.eSatisfactory(rules, epsiron = 0.3)
# Calculate cfexp for each row
targets = predict(mod, newdata = x.interests)
target.class = mod$classes
tweaked = mapply(function(x.interest, target, row.id) {
ytilde = target.class[-which(target %in% targets)]
res = tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE)
res.sug = res$suggest
res.sug$row_ids = row.id
res.sug
}, split(x.interests, seq(length(row.ids))), targets, row.ids,
SIMPLIFY = FALSE)
res.cf = do.call("rbind", tweaked)
ncols = ncol(res.cf)
cf = res.cf[, 1:(ncols-1)]
# revert dummy encoding
browser()
dum.vars = names(which(pred$predictor$data$feature.types == "categorical"))
for (var in dum.vars) {
cf = revert_dummy(var, cf)
}
# revert scaling
cf.classes = sapply(cf, class)
int.id = which(cf.classes != df.classes)
cf[, int.id] = data.frame(apply(cf[, int.id], MARGIN = 2,
function(x) as.integer(x)))
name.file = paste("cf", "tweaking", pred$learner.id, sep = "-")
pathtofile = file.path("../../saved_objects/data",
pred$task.id, paste(name.file, ".csv", sep = ""))
write.csv(res.cf, pathtofile, row.names = FALSE)
}
mapply(function(pred){feature_tweaking(pred)},
bm.models[rf.id])
dum.vars
cf
cf.classes
int.id
cf
center
scale
attr(center, "V8")
t(apply(cf, 1, function(r) print(r))
name.file = paste("cf", "tweaking", pred$learner.id, sep = "-")
pathtofile = file.path("../../saved_objects/data",
pred$task.id, paste(name.file, ".csv", sep = ""))
write.csv(res.cf, pathtofile, row.names = FALSE)
}
if (PARALLEL) {
parallelMap::parallelStartMulticore(5L)
}
mapply(function(pred){feature_tweaking(pred)},
bm.models[rf.id])
revert_dummy <-function(var,indata){
nam = names(indata)[grepl(var, names(indata))]
col = indata[, nam]
nams = str_remove(names(col), var)
val = names(col)[apply(col, 1, function(i) which(i == 1))]
val = str_remove(val, var)
indata[, nam[1]] = factor(val, levels = nams)
names(indata)[names(indata) == nam[1]] <- var
indata[, nam[2:length(nam)]] = NULL
return(indata)
}
feature_tweaking = function(pred) {
assert_true(pred$learner.id == "randomforest")
# Load info from folder
path = file.path("../../saved_objects/data",
pred$task.id)
row.ids = read.delim(file.path(path, "sampled_ids.txt"), header = FALSE)[,1]
df = read.csv(file.path(path, "data_encoded.csv"))
df = df[, !(names(df) %in% pred$predictor$data$y.names)]
df.classes = sapply(df, class)
center = read_json(file.path(path, "feature_center.json"))
scale = read_json(file.path(path, "feature_scale.json"))
x.interests = df[row.ids, ]
# Get model
mod = pred$predictor$model$learner.model$next.model$learner.model
class(mod) = "randomForest"
rules <- getRules(mod, ktree = 5L, resample = TRUE)
es.rf <- set.eSatisfactory(rules, epsiron = 0.3)
# Calculate cfexp for each row
targets = predict(mod, newdata = x.interests)
target.class = mod$classes
tweaked = mapply(function(x.interest, target, row.id) {
ytilde = target.class[-which(target %in% targets)]
res = tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE)
res.sug = res$suggest
res.sug$row_ids = row.id
res.sug
}, split(x.interests, seq(length(row.ids))), targets, row.ids,
SIMPLIFY = FALSE)
res.cf = do.call("rbind", tweaked)
ncols = ncol(res.cf)
cf = res.cf[, 1:(ncols-1)]
# revert dummy encoding
cf.classes = sapply(cf, class)
int.id = which(cf.classes != df.classes)
cf[, int.id] = data.frame(apply(cf[, int.id], MARGIN = 2,
function(x) as.integer(x)))
dum.vars = names(which(pred$predictor$data$feature.types == "categorical"))
for (var in dum.vars) {
cf = revert_dummy(var, cf)
}
browser()
# revert scaling
#t(apply(cf, 1, function(r)r*attr(cf,'scaled:scale') + attr(xs, 'scaled:center')))
#t(apply(cf, 1, function(r) print(r)))
name.file = paste("cf", "tweaking", pred$learner.id, sep = "-")
pathtofile = file.path("../../saved_objects/data",
pred$task.id, paste(name.file, ".csv", sep = ""))
write.csv(res.cf, pathtofile, row.names = FALSE)
}
revert_dummy <-function(var,indata){
nam = names(indata)[grepl(var, names(indata))]
col = indata[, nam]
nams = str_remove(names(col), var)
val = names(col)[apply(col, 1, function(i) which(i == 1))]
val = str_remove(val, var)
indata[, nam[1]] = factor(val, levels = nams)
names(indata)[names(indata) == nam[1]] <- var
indata[, nam[2:length(nam)]] = NULL
return(indata)
}
mapply(function(pred){feature_tweaking(pred)},
bm.models[rf.id])
t(apply(cf, 1, function(r) print(r)))
# revert scaling
cf.classes = sapply(cf, class)
cf.clsses
cf.classes
which(cf.class == "numeric")
# revert scaling
cf.classes = sapply(cf, class)
which(cf.classes == "numeric")
names(which(cf.classes == "numeric"))
nam.num = names(which(cf.classes == "numeric"))
scale[nam]
nam.num
nam = nam.num[1]
nam
scale[nam]
scale[[nam]]
scale[[nam]]
center[[nam]]
cf[, nam]*scale[[nam]] + center[[nam]]
cf.old = cf
cf[, nam] = cf[, nam]*scale[[nam]] + center[[nam]]
cf
x.interests
pred$predictor$data$get.x()[pred$sampled.rows]
x.interest.orig = pred$predictor$data$get.x()[row.ids, ]
x.interest.orig
x.interest
x.interests
cf.classes = sapply(x.interests, class)
nam.num = names(which(cf.classes == "numeric"))
for (nam in nam.num) {
x.interests[, nam] = x.interests[, nam]*scale[[nam]] + center[[nam]]
}
x.interests
nam = "Var1"
x.interests[, nam] = x.interests[, nam]*scale[[nam]
]
nam
nam = "V1"
x.interests[, nam] = x.interests[, nam]*scale[[nam]
]
x.interests$V1
x.interests = df[row.ids, ]
x.interests$V1
x.interest.orig = pred$predictor$data$get.x()[row.ids, ]
x.interest.orig
x.interest
x.interest[1, ]
x.interests[1, ]
new = x.interests[, nam]*scale[[nam]] + center[[nam]]
new
x.interest.orig$V1
feature_tweaking = function(pred) {
assert_true(pred$learner.id == "randomforest")
# Load info from folder
path = file.path("../../saved_objects/data",
pred$task.id)
row.ids = read.delim(file.path(path, "sampled_ids.txt"), header = FALSE)[,1]
df = read.csv(file.path(path, "data_encoded.csv"))
df = df[, !(names(df) %in% pred$predictor$data$y.names)]
df.classes = sapply(df, class)
center = read_json(file.path(path, "feature_center.json"))
scale = read_json(file.path(path, "feature_scale.json"))
x.interests = df[row.ids, ]
# Get model
mod = pred$predictor$model$learner.model$next.model$learner.model
class(mod) = "randomForest"
rules <- getRules(mod, ktree = 5L, resample = TRUE)
es.rf <- set.eSatisfactory(rules, epsiron = 0.3)
# Calculate cfexp for each row
targets = predict(mod, newdata = x.interests)
target.class = mod$classes
tweaked = mapply(function(x.interest, target, row.id) {
ytilde = target.class[-which(target %in% targets)]
res = tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE)
res.sug = res$suggest
res.sug$row_ids = row.id
res.sug
}, split(x.interests, seq(length(row.ids))), targets, row.ids,
SIMPLIFY = FALSE)
res.cf = do.call("rbind", tweaked)
ncols = ncol(res.cf)
cf = res.cf[, 1:(ncols-1)]
browser()
# revert dummy encoding
cf.classes = sapply(cf, class)
int.id = which(cf.classes != df.classes)
cf[, int.id] = data.frame(apply(cf[, int.id], MARGIN = 2,
function(x) as.integer(x)))
dum.vars = names(which(pred$predictor$data$feature.types == "categorical"))
for (var in dum.vars) {
cf = revert_dummy(var, cf)
}
# revert scaling
cf.classes = sapply(cf, class)
nam.num = names(which(cf.classes == "numeric"))
for (nam in nam.num) {
cf[, nam] = cf[, nam]*scale[[nam]] + center[[nam]]
}
name.file = paste("cf", "tweaking", pred$learner.id, sep = "-")
pathtofile = file.path("../../saved_objects/data",
pred$task.id, paste(name.file, ".csv", sep = ""))
write.csv(res.cf, pathtofile, row.names = FALSE)
}
mapply(function(pred){feature_tweaking(pred)},
bm.models[rf.id])
cf.classes
int.id
dum.vars
var = dum.vars[[1]]
cf = revert_dummy(var, cf)
cf
# revert scaling
cf.classes = sapply(cf, class)
cf.classes
nam.num = names(which(cf.classes == "numeric"))
for (nam in nam.num) {
cf[, nam] = cf[, nam]*scale[[nam]] + center[[nam]]
}
feature_tweaking = function(pred) {
assert_true(pred$learner.id == "randomforest")
# Load info from folder
path = file.path("../../saved_objects/data",
pred$task.id)
row.ids = read.delim(file.path(path, "sampled_ids.txt"), header = FALSE)[,1]
df = read.csv(file.path(path, "data_encoded.csv"))
df = df[, !(names(df) %in% pred$predictor$data$y.names)]
df.classes = sapply(df, class)
center = read_json(file.path(path, "feature_center.json"))
scale = read_json(file.path(path, "feature_scale.json"))
x.interests = df[row.ids, ]
# Get model
mod = pred$predictor$model$learner.model$next.model$learner.model
class(mod) = "randomForest"
rules <- getRules(mod, ktree = 5L, resample = TRUE)
es.rf <- set.eSatisfactory(rules, epsiron = 0.3)
# Calculate cfexp for each row
targets = predict(mod, newdata = x.interests)
target.class = mod$classes
tweaked = mapply(function(x.interest, target, row.id) {
ytilde = target.class[-which(target %in% targets)]
res = tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE)
res.sug = res$suggest
res.sug$row_ids = row.id
res.sug
}, split(x.interests, seq(length(row.ids))), targets, row.ids,
SIMPLIFY = FALSE)
res.cf = do.call("rbind", tweaked)
ncols = ncol(res.cf)
cf = res.cf[, 1:(ncols-1)]
# revert dummy encoding
cf.classes = sapply(cf, class)
int.id = which(cf.classes != df.classes)
cf[, int.id] = data.frame(apply(cf[, int.id], MARGIN = 2,
function(x) as.integer(x)))
dum.vars = names(which(pred$predictor$data$feature.types == "categorical"))
for (var in dum.vars) {
cf = revert_dummy(var, cf)
}
# revert scaling
cf.classes = sapply(cf, class)
nam.num = names(which(cf.classes == "numeric"))
for (nam in nam.num) {
cf[, nam] = cf[, nam]*scale[[nam]] + center[[nam]]
}
browser()
name.file = paste("cf", "tweaking", pred$learner.id, sep = "-")
pathtofile = file.path("../../saved_objects/data",
pred$task.id, paste(name.file, ".csv", sep = ""))
write.csv(res.cf, pathtofile, row.names = FALSE)
}
mapply(function(pred){feature_tweaking(pred)},
bm.models[rf.id])
cf
feature_tweaking = function(pred) {
assert_true(pred$learner.id == "randomforest")
# Load info from folder
path = file.path("../../saved_objects/data",
pred$task.id)
row.ids = read.delim(file.path(path, "sampled_ids.txt"), header = FALSE)[,1]
df = read.csv(file.path(path, "data_encoded.csv"))
df = df[, !(names(df) %in% pred$predictor$data$y.names)]
df.classes = sapply(df, class)
center = read_json(file.path(path, "feature_center.json"))
scale = read_json(file.path(path, "feature_scale.json"))
x.interests = df[row.ids, ]
# Get model
mod = pred$predictor$model$learner.model$next.model$learner.model
class(mod) = "randomForest"
rules <- getRules(mod, ktree = 5L, resample = TRUE)
es.rf <- set.eSatisfactory(rules, epsiron = 0.3)
# Calculate cfexp for each row
targets = predict(mod, newdata = x.interests)
target.class = mod$classes
tweaked = mapply(function(x.interest, target, row.id) {
ytilde = target.class[-which(target %in% targets)]
browser()
res = tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE)
res.sug = res$suggest
res.sug$row_ids = row.id
res.sug
}, split(x.interests, seq(length(row.ids))), targets, row.ids,
SIMPLIFY = FALSE)
res.cf = do.call("rbind", tweaked)
ncols = ncol(res.cf)
cf = res.cf[, 1:(ncols-1)]
# revert dummy encoding
cf.classes = sapply(cf, class)
int.id = which(cf.classes != df.classes)
cf[, int.id] = data.frame(apply(cf[, int.id], MARGIN = 2,
function(x) as.integer(x)))
dum.vars = names(which(pred$predictor$data$feature.types == "categorical"))
for (var in dum.vars) {
cf = revert_dummy(var, cf)
}
# revert scaling
cf.classes = sapply(cf, class)
nam.num = names(which(cf.classes == "numeric"))
for (nam in nam.num) {
cf[, nam] = cf[, nam]*scale[[nam]] + center[[nam]]
}
cf$row_ids = res.cf$row_ids
name.file = paste("cf", "tweaking", pred$learner.id, sep = "-")
pathtofile = file.path("../../saved_objects/data",
pred$task.id, paste(name.file, ".csv", sep = ""))
write.csv(res.cf, pathtofile, row.names = FALSE)
}
mapply(function(pred){feature_tweaking(pred)},
bm.models[rf.id])
seq_len(mu)
mu = 20
seq_len(mu)
seq_along(mu)
seq(1, mu)
mu
seq_len(mu)
mu = 2
res = lapply(seq_len(mu), function() tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE))
res = lapply(seq_len(mu), function(x) tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE))
res
res = lapply(seq_len(mu), function(x){
tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde,
.dopar = TRUE)$suggest
})
res.sug = do.call("rbind", res)
res.sug
?tweak
res = lapply(seq_len(mu), function(x){
tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde)$suggest
})
res
rules <- getRules(mod, ktree = 50L, resample = TRUE)
es.rf <- set.eSatisfactory(rules)
# Calculate cfexp for each row
targets = predict(mod, newdata = x.interests)
target.class = mod$classes
tweaked = mapply(function(x.interest, target, row.id) {
ytilde = target.class[-which(target %in% targets)]
browser()
res = lapply(seq_len(mu), function(x){
tweak(es.rf, mod, newdata= x.interest,
label.from = as.character(target), label.to = ytilde)$suggest
})
res.sug = do.call("rbind", res)
res.sug$row_ids = row.id
res.sug
}, split(x.interests, seq(length(row.ids))), targets, row.ids,
SIMPLIFY = FALSE)
res
tweak(es.rf, mod, newdata= x.interest[rep(seq_len(nrow(x.interest)), each = 5), ],
label.from = as.character(target), label.to = ytilde)$suggest
rules <- getRules(mod, ktree = NULL, resample = TRUE)
es.rf <- set.eSatisfactory(rules)
targets = predict(mod, newdata = x.interests)
target.class = mod$classes
tweaked = mapply(function(x.interest, target, row.id) {
ytilde = target.class[-which(target %in% targets)]
browser()
res.sug = tweak(es.rf, mod, newdata= x.interest[rep(seq_len(nrow(x.interest)), each = 5), ],
label.from = as.character(target), label.to = ytilde)$suggest
res.sug$row_ids = row.id
res.sug
}, split(x.interests, seq(length(row.ids))), targets, row.ids,
SIMPLIFY = FALSE)
res.sug
